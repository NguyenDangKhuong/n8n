{
  "updatedAt": "2025-11-07T16:05:16.258Z",
  "createdAt": "2025-11-07T16:05:16.258Z",
  "id": "7dAG0hGUIHUoLyON",
  "name": "My workflow 2",
  "description": null,
  "active": false,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "content": "## üîÄ Input Mode Router\n\n**Purpose:** Branches to image-to-video if file uploaded, else text-to-video with refinement.\n\n**Note:** Switch checks filename; ensures GPT-5 processes text prompts.",
        "height": 192,
        "width": 332,
        "color": 3
      },
      "id": "e2b2bc67-452a-472a-89ba-09a10e8471f8",
      "name": "Note: Mode Router",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        752,
        656
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## üñºÔ∏è Temp Image Upload\n\n**Purpose:** Uploads reference image to tmpfiles.org for Sora image-to-video.\n\n**Note:** Multipart POST; swaps URL to /dl/ for direct API access.",
        "height": 192,
        "width": 332,
        "color": 6
      },
      "id": "f61817ff-8405-493c-8010-90bf84485c18",
      "name": "Note: Image Upload",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1216,
        96
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## ü§ñ Prompt Refiner\n\n**Purpose:** Uses GPT-5 to enhance text prompts for Sora 2 text-to-video mode.\n\n**Note:** Mandatory for text branch; outputs JSON with refined prompt, ratio, duration.",
        "height": 192,
        "width": 332,
        "color": 5
      },
      "id": "2b4ad923-e1bd-4db6-b928-f0cb9457ccfa",
      "name": "Note: Prompt Refiner",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        960,
        944
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## üîç JSON Output Parser\n\n**Purpose:** Validates GPT-5 response against schema for clean API params.\n\n**Note:** Ensures prompt (50-4000 chars), ratio (16:9/9:16), duration (4/8/12).",
        "height": 192,
        "width": 332,
        "color": 3
      },
      "id": "7ead7b2d-f1d0-4c88-8d55-e0fa203e5881",
      "name": "Note: JSON Parser",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1392,
        960
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## üé• Text-to-Video Call\n\n**Purpose:** Submits refined prompt to fal.ai Sora 2 text endpoint (pro if selected).\n\n**Note:** Uses 720p res; calls /text-to-video or /pro; returns request_id for polling.",
        "height": 192,
        "width": 332,
        "color": 5
      },
      "id": "13591726-0250-4458-a468-cf39e325d041",
      "name": "Note: Text-to-Video",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1760,
        768
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## üñºÔ∏è Image-to-Video Call\n\n**Purpose:** Sends raw prompt + image URL to fal.ai Sora 2 image endpoint.\n\n**Note:** Auto res; calls /image-to-video or /pro; uses form ratio/duration directly.",
        "height": 192,
        "width": 332,
        "color": 5
      },
      "id": "31ea46bd-a3fe-4c92-871a-7202f78e10e6",
      "name": "Note: Image-to-Video",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        1712,
        160
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "formTitle": "Create a Video using Sora 2",
        "formFields": {
          "values": [
            {
              "fieldLabel": "Prompt",
              "requiredField": true
            },
            {
              "fieldLabel": "Aspect Ratio",
              "fieldType": "dropdown",
              "fieldOptions": {
                "values": [
                  {
                    "option": "9:16 (vertical)"
                  },
                  {
                    "option": "16:9 (Horizontal)"
                  }
                ]
              },
              "requiredField": true
            },
            {
              "fieldLabel": "Model",
              "fieldType": "checkbox",
              "fieldOptions": {
                "values": [
                  {
                    "option": "sora-2"
                  },
                  {
                    "option": "sora-2-pro"
                  }
                ]
              },
              "limitSelection": "exact",
              "requiredField": true
            },
            {
              "fieldLabel": "Lenght",
              "fieldType": "checkbox",
              "fieldOptions": {
                "values": [
                  {
                    "option": "4s"
                  },
                  {
                    "option": "8s"
                  },
                  {
                    "option": "12s"
                  }
                ]
              },
              "limitSelection": "exact",
              "requiredField": true
            },
            {
              "fieldLabel": "Image",
              "fieldType": "file",
              "multipleFiles": false,
              "acceptFileTypes": ".jpg,.jpeg,.png"
            }
          ]
        },
        "options": {
          "appendAttribution": false
        }
      },
      "id": "e7e6cd02-f72b-44c2-8116-831e33a74a3c",
      "name": "Video Input Form",
      "type": "n8n-nodes-base.formTrigger",
      "position": [
        864,
        464
      ],
      "webhookId": "45e6e98c-ff89-46c5-b143-c5d4c9dab16f",
      "typeVersion": 2.3
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "=User Query: {{ $json.Prompt }}\n\nApect Ratio: {{ $json['Aspect Ratio'] }}\n\nLenght: {{ $json.Lenght[0] }}",
        "hasOutputParser": true,
        "messages": {
          "messageValues": [
            {
              "message": "=You are an expert AI video prompt engineer specializing in OpenAI's Sora 2 video generation model. Your role is to transform user input into professionally structured, cinematic prompts optimized for high-quality video generation.\n\n## Core Principles\n\n1. **Brevity for Reliability**: Shorter clips (4s) follow instructions more reliably than longer ones. Recommend 4s duration unless user specifically needs longer content.\n\n2. **Specificity Over Vagueness**: Replace abstract concepts with concrete, visual details. Transform \"beautiful street\" into \"wet asphalt, zebra crosswalk, neon signs reflecting in puddles.\"\n\n3. **One Beat Per Shot**: Each shot should contain ONE clear camera movement and ONE clear subject action. Avoid cramming multiple complex actions into a single clip.\n\n4. **Cinematic Thinking**: Treat prompts as storyboard descriptions or cinematographer briefs, not casual requests.\n\n## Prompt Structure Framework\n\nOrganize enhanced prompts using this hierarchy:\n\n### 1. Style & Format (Optional but Powerful)\n- Establish overall aesthetic early: \"1970s film,\" \"IMAX aerial,\" \"handheld documentary\"\n- Film stock references: \"35mm film,\" \"16mm with grain,\" \"digital capture\"\n- Color treatment: \"Kodak warm grade,\" \"teal and orange palette,\" \"desaturated noir\"\n\n### 2. Scene Description\n- Setting and environment with specific visual details\n- Character descriptions (clothing, age, demeanor)\n- Atmospheric elements (weather, time of day, lighting quality)\n- Props and set dressing that matter to the shot\n\n### 3. Cinematography\n**Camera shot**: Specify framing and angle\n- Examples: \"wide establishing shot, eye level,\" \"medium close-up, slight low angle,\" \"aerial wide shot, downward tilt\"\n\n**Lens/DOF**: When detail matters\n- Examples: \"35mm lens, shallow depth of field,\" \"50mm with background softness,\" \"wide angle for environmental context\"\n\n**Camera movement**: Keep it simple and precise\n- Examples: \"slow push-in,\" \"dolly left to right,\" \"static handheld,\" \"crane up revealing skyline\"\n\n**Mood**: Emotional tone\n- Examples: \"tense and cinematic,\" \"warm and nostalgic,\" \"playful suspense\"\n\n### 4. Lighting & Palette\nDescribe light quality and color anchors:\n- Light quality: \"soft window light,\" \"hard single source,\" \"diffused overhead\"\n- Direction: \"from camera left,\" \"backlit,\" \"rim lighting\"\n- Color anchors: Name 3-5 specific colors for palette consistency\n- Examples: \"warm key from overhead, cool rim from window; palette: amber, cream, teal\"\n\n### 5. Actions (Time-Based Beats)\nBreak down motion into countable beats:\n- Use specific verbs and counts: \"takes four steps,\" \"pauses for two seconds,\" \"turns and catches\"\n- Avoid: \"walks around\" ‚Üí Use: \"takes three steps forward, pauses, looks left\"\n- Keep actions achievable within the duration\n\n### 6. Dialogue (If Applicable)\nFormat dialogue clearly:\n- Place in dedicated block with speaker labels\n- Keep lines short and natural (4s = 1-2 exchanges, 8s = 3-4 exchanges)\n- Example format:\n  ```\n  Dialogue:\n  - Character A: \"Short, natural line.\"\n  - Character B: \"Response that fits timing.\"\n  ```\n\n### 7. Audio/Sound (Optional)\nSuggest diegetic sounds to establish rhythm:\n- Examples: \"distant traffic hum,\" \"coffee machine hiss,\" \"paper rustle\"\n- Note: This is for pacing cues, not full soundtracks\n\n## Enhancement Guidelines\n\n### What to ADD:\n- Concrete visual details (colors, textures, specific objects)\n- Professional cinematography terms (shot types, camera movements)\n- Lighting direction and quality\n- Precise action beats with timing\n- Style references that set aesthetic tone\n- Specific color palette (3-5 colors)\n\n### What to REPLACE:\n- \"Beautiful\" ‚Üí Specific visual qualities\n- \"Moves\" ‚Üí Precise action with counts\n- \"Nice lighting\" ‚Üí Light source, direction, quality\n- \"Cinematic\" ‚Üí Actual film/lens specifications\n- \"Interesting angle\" ‚Üí Specific shot type and framing\n\n### What to AVOID:\n- Multiple complex actions in one shot\n- Vague descriptors without visual specifics\n- Requesting duration/resolution in prose (these are API parameters)\n- Overcrowding shots with too many elements\n- Abstract emotions without visual manifestations\n\n## Duration Recommendations\n\nBased on user intent:\n- **4 seconds**: Default recommendation. Most reliable for instruction following. Best for single clear action.\n- **8 seconds**: When user needs slightly more development. Warn that this may be less reliable; suggest stitching two 4s clips instead.\n- **12 seconds**: Only when explicitly requested. Strongly recommend breaking into multiple 4s shots for better control.\n\n## Aspect Ratio Selection\n\n- **16:9**: Landscape, traditional video, cinematic scenes, wide vistas, desktop viewing\n- **9:16**: Portrait, social media (TikTok, Instagram Stories, Reels), mobile-first content, vertical stories\n\n## Transformation Process\n\n1. **Analyze** user input for core intent\n2. **Identify** missing cinematic elements (camera, lighting, specific actions)\n3. **Expand** vague descriptions into concrete visuals\n4. **Structure** using the framework above\n5. **Optimize** for the chosen duration\n6. **Balance** detail with creative freedom based on user needs\n\n## Examples of Weak ‚Üí Strong Transformations\n\n**Weak**: \"A person walking down a street at night\"\n**Strong**: \"Style: Handheld 35mm with natural grain. A woman in a red coat takes five measured steps down a wet cobblestone street. Amber streetlights create pools of warm light; cool shadows between them. Camera: medium tracking shot, following from behind at shoulder level. Mood: solitary, urban noir. Lighting: practical streetlights only; reflections in puddles.\"\n\n**Weak**: \"Make it look cinematic\"\n**Strong**: \"Camera: wide shot, slow dolly-in. Lens: 40mm spherical with shallow DOF. Lighting: golden hour natural key from camera left, edge light on subject. Palette: warm amber, deep teal, cream. Mood: nostalgic, intimate.\"\n\n## Response Format\n\nAlways output your enhanced prompt as a JSON object with exactly three fields:\n- \"prompt\": The fully enhanced, professionally structured prompt (50-4000 characters)\n- \"aspect_ratio\": Either \"16:9\" or \"9:16\"\n- \"duration\": Either 4, 8, or 12 (integer, in seconds)\n\nAim for 60-150 words for standard prompts, more for complex cinematic shots requiring detailed specifications. Include professional cinematographic language while maintaining clarity."
            }
          ]
        },
        "batching": {}
      },
      "id": "f38b61bc-c6cb-4119-86c1-d551f6b1fc77",
      "name": "Prompt Refiner",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "position": [
        1312,
        608
      ],
      "typeVersion": 1.7
    },
    {
      "parameters": {
        "schemaType": "manual",
        "inputSchema": "{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"title\": \"Sora2VideoGenerationRequest\",\n  \"description\": \"Simplified schema for Sora 2 video generation with enhanced prompts\",\n  \"type\": \"object\",\n  \"required\": [\"prompt\", \"aspect_ratio\", \"duration\"],\n  \"properties\": {\n    \"prompt\": {\n      \"type\": \"string\",\n      \"description\": \"The fully enhanced, professionally structured prompt optimized for Sora 2 video generation with cinematography details, specific actions, lighting, and visual specifics\",\n      \"minLength\": 50,\n      \"maxLength\": 4000\n    },\n    \"aspect_ratio\": {\n      \"type\": \"string\",\n      \"enum\": [\"16:9\", \"9:16\"],\n      \"description\": \"Video aspect ratio. 16:9 for landscape/cinematic, 9:16 for portrait/social media\"\n    },\n    \"duration\": {\n      \"type\": \"integer\",\n      \"enum\": [4, 8, 12],\n      \"description\": \"Video duration in seconds. 4s is most reliable, 8s and 12s may have reduced instruction-following accuracy\"\n    }\n  }\n}"
      },
      "id": "b19fb367-7ccd-4e11-bb2a-af4e951d8e0a",
      "name": "JSON Output Parser",
      "type": "@n8n/n8n-nodes-langchain.outputParserStructured",
      "position": [
        1456,
        784
      ],
      "typeVersion": 1.3
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=https://tmpfiles.org/api/v1/upload",
        "sendBody": true,
        "contentType": "multipart-form-data",
        "bodyParameters": {
          "parameters": [
            {
              "parameterType": "formBinaryData",
              "name": "file",
              "inputDataFieldName": "Image"
            }
          ]
        },
        "options": {}
      },
      "id": "5225f0e5-d3d7-4d7d-8c59-4ee45c68a238",
      "name": "Temp Image Upload",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1360,
        336
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=https://queue.fal.run/fal-ai/sora-2/text-to-video{{ $('Video Input Form').item.json.Model[0] === 'sora-2-pro' ? '/pro' : '' }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"prompt\": \"{{ JSON.stringify($('Prompt Refiner').item.json.output.prompt.replaceAll(/\\\\n/g, '')).slice(1, -1) }}\",\n  \"resolution\": \"720p\",\n  \"aspect_ratio\": \"{{ $('Prompt Refiner').item.json.output.aspect_ratio }}\",\n  \"duration\": {{ $('Prompt Refiner').item.json.output.duration }}\n}",
        "options": {}
      },
      "id": "b8bbebf2-614e-4064-9877-2d60cfb7599c",
      "name": "Text-to-Video Call",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1616,
        608
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "dfdd231a-d2f6-4973-a068-ac13f2bbd506",
                    "operator": {
                      "type": "string",
                      "operation": "notEmpty",
                      "singleValue": true
                    },
                    "leftValue": "={{ $json.Image.filename }}",
                    "rightValue": ""
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "Image to Video"
            },
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "68ac0648-f33e-4394-805d-a8a9b788f1df",
                    "operator": {
                      "type": "string",
                      "operation": "empty",
                      "singleValue": true
                    },
                    "leftValue": "={{ $json.Image.filename }}",
                    "rightValue": ""
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "Text to Video "
            }
          ]
        },
        "options": {}
      },
      "id": "c3b64fb0-c1f5-47e9-a121-20a73871068c",
      "name": "Input Mode Router",
      "type": "n8n-nodes-base.switch",
      "position": [
        1072,
        464
      ],
      "typeVersion": 3.3
    },
    {
      "parameters": {
        "method": "POST",
        "url": "=https://queue.fal.run/fal-ai/sora-2/image-to-video{{ $('Video Input Form').item.json.Model[0] === 'sora-2-pro' ? '/pro' : '' }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"prompt\": \"{{ JSON.stringify($('Video Input Form').item.json.Prompt.replaceAll(/\\\\n/g, '')).slice(1, -1) }}\",\n  \"resolution\": \"auto\",\n  \"aspect_ratio\": \"{{ $('Video Input Form').item.json['Aspect Ratio'].replaceAll(' (vertical)', '').replaceAll(' (Horizontal)', '') }}\",\n  \"duration\": {{ $('Video Input Form').item.json.Lenght[0].replaceAll('s', '') }},\n  \"image_url\": \"{{ $json.data.url.replaceAll('.org/', '.org/dl/') }}\"\n}",
        "options": {}
      },
      "id": "946a4539-904a-4d0b-a52d-fe430ee7c536",
      "name": "Image-to-Video Call",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        1536,
        336
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "amount": 60
      },
      "id": "a1836922-502d-4b4a-a2ae-55a0541d2b94",
      "name": "Wait 60 Seconds",
      "type": "n8n-nodes-base.wait",
      "position": [
        1808,
        432
      ],
      "webhookId": "caad73e3-58d8-4fbd-a3e9-c42424f2d1ee",
      "typeVersion": 1.1
    },
    {
      "parameters": {
        "url": "=https://queue.fal.run/fal-ai/sora-2/requests/{{ $json.request_id }}/status",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "options": {}
      },
      "id": "a73c342c-3f1c-45cd-afcf-98fe51a75f49",
      "name": "Status Check",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        2016,
        432
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "rules": {
          "values": [
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "d8b8dbdc-1ad9-4ab9-8b2d-e76fd5db0899",
                    "operator": {
                      "type": "string",
                      "operation": "equals"
                    },
                    "leftValue": "={{ $json.status }}",
                    "rightValue": "COMPLETED"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "Done"
            },
            {
              "conditions": {
                "options": {
                  "version": 2,
                  "leftValue": "",
                  "caseSensitive": true,
                  "typeValidation": "strict"
                },
                "combinator": "and",
                "conditions": [
                  {
                    "id": "9c10982c-5f8c-4eec-9b8a-f4b42e99ecf9",
                    "operator": {
                      "type": "string",
                      "operation": "notEquals"
                    },
                    "leftValue": "={{ $json.status }}",
                    "rightValue": "COMPLETED"
                  }
                ]
              },
              "renameOutput": true,
              "outputKey": "Progress"
            }
          ]
        },
        "options": {}
      },
      "id": "d9907452-db6c-49fd-9144-a758bbe34ad5",
      "name": "Status Router",
      "type": "n8n-nodes-base.switch",
      "position": [
        2224,
        432
      ],
      "typeVersion": 3.2
    },
    {
      "parameters": {
        "url": "=https://queue.fal.run/fal-ai/sora-2/requests/{{ $json.request_id }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "options": {}
      },
      "id": "8f4e2071-883b-48bf-abd2-2f4380aabaff",
      "name": "Retrieve Video",
      "type": "n8n-nodes-base.httpRequest",
      "position": [
        2416,
        416
      ],
      "typeVersion": 4.2
    },
    {
      "parameters": {
        "operation": "completion",
        "respondWith": "redirect",
        "redirectUrl": "={{ $json.video.url }}",
        "options": {}
      },
      "id": "71b789b7-f113-4792-b1fe-6c020067f81c",
      "name": "Video Redirect",
      "type": "n8n-nodes-base.form",
      "position": [
        2624,
        416
      ],
      "webhookId": "7b9192c7-c2ff-47b1-b893-bfbea42dd268",
      "typeVersion": 2.3
    },
    {
      "parameters": {
        "content": "# üé¨ Sora 2 Video Generator via Fal with GPT-5 Refinement\n\n## üìã What This Template Does\nGenerate videos using OpenAI's Sora 2 via fal.ai's four endpoints (text-to-video, text-to-video/pro, image-to-video, image-to-video/pro). Accepts form inputs for prompts, aspect ratios, models, durations (4-12s), and optional images. For text mode, GPT-5 refines prompts for cinematic quality; image mode uses raw input. Polls status asynchronously and redirects to the final video.\n\n## üîß Prerequisites\n- n8n with HTTP Request and LangChain nodes\n- fal.ai account\n- OpenAI account (GPT-5 access)\n\n## üîë Required Credentials\n\n### fal.ai API Setup\n1. fal.ai ‚Üí Dashboard ‚Üí API Keys\n2. Generate key with sora-2 permissions\n3. n8n: Header Auth (\"fal.ai\", Header: \"Authorization\", Value: \"Key [Your Key]\")\n\n### OpenAI API Setup\n1. platform.openai.com ‚Üí API Keys ‚Üí Create secret key\n2. n8n: OpenAI API credential (paste key, select GPT-5)\n\n## ‚öôÔ∏è Configuration Steps\n1. Import JSON (Settings ‚Üí Import)\n2. Assign creds to HTTP/LLM nodes\n3. Activate‚Äîuse form URL from trigger\n4. Test prompt; check executions\n5. Tune polling for longer clips\n\n## üéØ Use Cases\n- Social: 9:16 Reels from refined text (e.g., product anims)\n- Marketing: Image-to-8s promos (e.g., logo intros)\n- Education: 4s explainers (e.g., science demos)\n- Dev: Backend for app video gen\n\n## ‚ö†Ô∏è Troubleshooting\n- Quota fail: Check fal.ai usage; upgrade/add waits\n- Refinement error: Verify GPT-5 schema output\n- Image reject: JPG/PNG <10MB; test tmpfiles\n- Poll timeout: Bump wait to 120s; add retry IF",
        "height": 1184,
        "width": 696,
        "color": 4
      },
      "id": "aeb00d5e-3703-45e8-900d-8134fe747097",
      "name": "Overview Note8",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        0,
        0
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## üìù Video Input Form\n\n**Purpose:** Captures user prompt, ratio, model, duration, and optional image via web form.\n\n**Note:** Required fields validated; activates webhook URL on workflow start.",
        "height": 192,
        "width": 332,
        "color": 6
      },
      "id": "72dd522b-15d4-4903-90dd-7c60dc737681",
      "name": "Note: Form Trigger1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        720,
        192
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "content": "## ‚è≥ Status Polling Loop\n\n**Purpose:** Waits 60s, checks Sora status, loops until COMPLETED.\n\n**Note:** Switch routes to result or retry; handles all four endpoints uniformly.",
        "height": 192,
        "width": 332,
        "color": 2
      },
      "id": "d24ffbc1-2991-4201-af61-637f9e58410b",
      "name": "Note: Polling Loop1",
      "type": "n8n-nodes-base.stickyNote",
      "position": [
        2160,
        656
      ],
      "typeVersion": 1
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-5",
          "cachedResultName": "gpt-5"
        },
        "options": {}
      },
      "id": "b05d6a44-f3b4-474a-91d2-cff96c8a1ae6",
      "name": "Refiner Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [
        1312,
        784
      ],
      "typeVersion": 1.2
    }
  ],
  "connections": {
    "Status Check": {
      "main": [
        [
          {
            "node": "Status Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Refiner Model": {
      "ai_languageModel": [
        [
          {
            "node": "Prompt Refiner",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Status Router": {
      "main": [
        [
          {
            "node": "Retrieve Video",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait 60 Seconds",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prompt Refiner": {
      "main": [
        [
          {
            "node": "Text-to-Video Call",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Retrieve Video": {
      "main": [
        [
          {
            "node": "Video Redirect",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait 60 Seconds": {
      "main": [
        [
          {
            "node": "Status Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Video Input Form": {
      "main": [
        [
          {
            "node": "Input Mode Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Input Mode Router": {
      "main": [
        [
          {
            "node": "Temp Image Upload",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prompt Refiner",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Temp Image Upload": {
      "main": [
        [
          {
            "node": "Image-to-Video Call",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "JSON Output Parser": {
      "ai_outputParser": [
        [
          {
            "node": "Prompt Refiner",
            "type": "ai_outputParser",
            "index": 0
          }
        ]
      ]
    },
    "Text-to-Video Call": {
      "main": [
        [
          {
            "node": "Wait 60 Seconds",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Image-to-Video Call": {
      "main": [
        [
          {
            "node": "Wait 60 Seconds",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": {},
  "versionId": "7cb60325-335a-47a4-b035-72162c3fc3eb",
  "activeVersionId": null,
  "versionCounter": 1,
  "triggerCount": 0,
  "tags": [],
  "shared": [
    {
      "updatedAt": "2025-11-07T16:05:16.261Z",
      "createdAt": "2025-11-07T16:05:16.261Z",
      "role": "workflow:owner",
      "workflowId": "7dAG0hGUIHUoLyON",
      "projectId": "1uTvCtZTXcZZgYo6",
      "project": {
        "updatedAt": "2025-11-07T10:21:21.281Z",
        "createdAt": "2025-11-07T10:17:33.127Z",
        "id": "1uTvCtZTXcZZgYo6",
        "name": "Khuong Nguyen <nguyendangkhuong96@gmail.com>",
        "type": "personal",
        "icon": null,
        "description": null,
        "creatorId": "9896ea82-dabd-4a0c-aef6-2e69d1cb5764"
      }
    }
  ]
}